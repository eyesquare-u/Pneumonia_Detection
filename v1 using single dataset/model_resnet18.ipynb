{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "future-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "executive-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mediterranean-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rising-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'train' : ImageFolder(root = './train', transform = image_transforms),\n",
    "        'test' : ImageFolder(root = './test', transform = image_transforms),\n",
    "        'val' : ImageFolder(root = './val', transform = image_transforms)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "documentary-portable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'NORMAL': 0, 'PNEUMONIA': 1},\n",
       " {'NORMAL': 0, 'PNEUMONIA': 1},\n",
       " {'NORMAL': 0, 'PNEUMONIA': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].class_to_idx, data['test'].class_to_idx, data['val'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bigger-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train' : DataLoader(data['train'], batch_size = 100, shuffle = True),\n",
    "               'test' : DataLoader(data['test'], batch_size = 100, shuffle = True),\n",
    "               'val' : DataLoader(data['val'], batch_size = 100, shuffle = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "white-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res18 = models.resnet18(pretrained=True)\n",
    "model_res18.fc = nn.Linear(model_res18.fc.in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caroline-skill",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "social-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_res18.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "african-istanbul",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3327598a90a44be9167807a62d041d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "training_loss:  tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "validation_loss:  tensor(0.6040, device='cuda:0')\n",
      "EPOCH 2\n",
      "training_loss:  tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "validation_loss:  tensor(0.1005, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in tqdm(range(1,epochs+1)):\n",
    "    \n",
    "    # Training Loop\n",
    "    for image, label in dataloaders['train']:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        model_res18.zero_grad()\n",
    "        prediction = model_res18(image)\n",
    "        loss = criterion(prediction, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"EPOCH\", epoch)\n",
    "    print('training_loss: ', loss)\n",
    "    train_loss.append(loss)\n",
    "    \n",
    "    # Evaluation Loop\n",
    "    model_res18.eval()\n",
    "    with torch.no_grad():\n",
    "        for image, label in dataloaders['val']:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "\n",
    "            prediction = model_res18(image)\n",
    "            loss = criterion(prediction, label)\n",
    "    print('validation_loss: ', loss)\n",
    "    val_loss.append(loss)\n",
    "    \n",
    "    model_res18.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "legitimate-corps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.814\n",
      "correct  508\n",
      "total 624\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "ground_truth = []\n",
    "predicted_results = []\n",
    "model_res18.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image, label in dataloaders['test']:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        prediction = model_res18(image)\n",
    "        #loss = loss_fun(prediction, label)\n",
    "        #print(prediction)\n",
    "        for k in range(len(prediction)):\n",
    "            #print(k)\n",
    "            #print(prediction)\n",
    "            #print(label)\n",
    "            ground_truth.append(label[k].item())\n",
    "            predicted_results.append(torch.argmax(prediction[k]).item())\n",
    "            \n",
    "            if torch.argmax(prediction[k]) == label[k]:\n",
    "                correct+=1\n",
    "                #print(image.shape)\n",
    "            total += 1\n",
    "\n",
    "#validation_loss.append(loss)    \n",
    "#print('validation_loss: ', loss)\n",
    "print('accuracy: ', round(correct/total, 3))\n",
    "print('correct ', correct)\n",
    "print('total', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "german-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expired-library",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120, 114],\n",
       "       [  2, 388]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(ground_truth, predicted_results)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "labeled-advocate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.51      0.67       234\n",
      "           1       0.77      0.99      0.87       390\n",
      "\n",
      "    accuracy                           0.81       624\n",
      "   macro avg       0.88      0.75      0.77       624\n",
      "weighted avg       0.85      0.81      0.80       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ground_truth, predicted_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-confidence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
